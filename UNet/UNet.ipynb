{"cells":[{"cell_type":"markdown","metadata":{"id":"fSJ6i10nNr8p"},"source":["# NAVARCH 565 FA 23 Homework 4\n","\n","Before we start, please put your name and UMID in following format\n","\n",": Firstname LASTNAME, #00000000   //   e.g.) Joey WILSON, #12345678"],"id":"fSJ6i10nNr8p"},{"cell_type":"markdown","metadata":{"id":"raKYJjAnNtVM"},"source":["**Your Answer:**   "],"id":"raKYJjAnNtVM"},{"cell_type":"markdown","metadata":{"id":"F9qBWNKfRG57"},"source":["# Objectives\n","\n","This assignment will be more hands-off than the previous perception problems. In the assignment, we will learn about convolutional neural networks and create a U-Net for semantic segmentation of images. You will be free to modify and create your own network. At the end of the assignment, you will generate predictions on a test set and be graded on the mean IoU of your predictions."],"id":"F9qBWNKfRG57"},{"cell_type":"markdown","source":["# Grading\n","All points from this assignment will come from evaluation on the test set. We will generate predictions on every tenth frame of the test set for submission to the autograder. This problem is worth 200 points including 50 points of extra credit. Points will be assigned by the mIoU metric as\n","\n","$$\n","\\text{score} = 200 \\frac{\\text{mIoU}}{30}\n","$$\n","\n","meaning that a score of 30% will obtain all extra credit, and a score of 22.5% will obtain full credit."],"metadata":{"id":"Hs9j7MqFB6-I"},"id":"Hs9j7MqFB6-I"},{"cell_type":"markdown","metadata":{"id":"1SR5DR15NkH5"},"source":["# Setup Code\n","Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n","\n","First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."],"id":"1SR5DR15NkH5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBW2G99ZNhCg"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"],"id":"eBW2G99ZNhCg"},{"cell_type":"markdown","metadata":{"id":"H2XlLu5rNnl_"},"source":["### Google Colab Setup\n","\n","Next we need to run a few commands to set up our environment on Google Colab.\n","Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account."],"id":"H2XlLu5rNnl_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIn1ad1cNn0U"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"YIn1ad1cNn0U"},{"cell_type":"markdown","metadata":{"id":"zjMrPtCeNzUQ"},"source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below. If everything is working correctly then running the folowing cell should print the filenames from the assignment:\n","\n","```\n","['UNet.ipynb',  'Problem2.py', 'Labels.txt']\n","```"],"id":"zjMrPtCeNzUQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_0ieFYpN0_S"},"outputs":[],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 2023FA folder and put all the files under A4/UNet folder, then '2023FA/A4'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"2023FA/A4/UNet\"\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"id":"A_0ieFYpN0_S"},{"cell_type":"markdown","source":["Next we have some standard imports"],"metadata":{"id":"tKAfWajmDfNz"},"id":"tKAfWajmDfNz"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vi7D1FtN5W-"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()"],"id":"2vi7D1FtN5W-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4e6f54d6"},"outputs":[],"source":["from Problem2 import *\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np"],"id":"4e6f54d6"},{"cell_type":"markdown","metadata":{"id":"yIhqY4DbU6Fm"},"source":["Next we will check if a GPU is available"],"id":"yIhqY4DbU6Fm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9763ba64"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"id":"9763ba64"},{"cell_type":"markdown","metadata":{"id":"AVvGyj-xVFa4"},"source":["# Data Visualization\n","\n","In this assignment we will be working with camera images and pixel-wise semantic segmentation labels.\n","\n","First, download the data from https://curly-dataset-public.s3.us-east-2.amazonaws.com/NA565/UNet/StudentData/Student.zip and unzip it to create a Train, Test, and Val folder. Place the files into a Data folder and add the path in the cell below. Move the `Labels.txt` file to Data folder.\n","\n","\n","\n","Run the cells below to visualize some of the example images from the dataset."],"id":"AVvGyj-xVFa4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-Rgtl0wVUwX"},"outputs":[],"source":["batch_size = 2\n","DATA_PATH = os.path.join(GOOGLE_DRIVE_PATH, \"Data\")\n","\n","trainset = ImageSegmentation(DATA_PATH, \"Train\", transform=transform_train(), device=device)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, collate_fn=trainset.collate_fn)\n","\n","valset = ImageSegmentation(DATA_PATH, \"Val\", transform=transform_test(), device=device)\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n","                                         shuffle=True, collate_fn=valset.collate_fn)"],"id":"G-Rgtl0wVUwX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8e51951e"},"outputs":[],"source":["def imshow(img):\n","    img = img / 2 + 0.5     # un-normalize\n","    npimg = img.detach().cpu().numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","def imshow_labels(img):\n","    npimg = img.detach().cpu().numpy()\n","    plt.imshow(npimg)\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","demo_image = images[0, :, :, :]\n","imshow(demo_image)\n","# show labels\n","demo_label = labels[0, :, :, :]\n","imshow_labels(demo_label)"],"id":"8e51951e"},{"cell_type":"markdown","metadata":{"id":"W_jAZ8SfVOJ-"},"source":["Notice how the ground truth is a color-coded image? The cell below takes the colors and converts each color to an integer label for our network to learn."],"id":"W_jAZ8SfVOJ-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1effefb2"},"outputs":[],"source":["label_file = open(os.path.join(DATA_PATH, \"Labels.txt\"), \"r\")\n","class_dict = {}\n","\n","i = 0\n","label_file.readline()\n","for line in label_file:\n","    text = line.split(\"\\n\")[0]\n","    tokens = text.split(\" \")\n","    rgb = np.array([int(tokens[1]), int(tokens[2]), int(tokens[3])])\n","    class_dict[i] = rgb\n","    i += 1\n","\n","# Convert colored image to labels\n","def to_labels(label_img, color_to_label):\n","    B, H, W, C = label_img.shape\n","    labels = torch.zeros((B, H, W, 1), device=label_img.device)\n","    for i, rgb in color_to_label.items():\n","        mask = (label_img[:, :, :, 0] == rgb[0]) & (label_img[:, :, :, 1] == rgb[1]) & (label_img[:, :, :, 2] == rgb[2])\n","        labels[mask] = i\n","    return labels"],"id":"1effefb2"},{"cell_type":"markdown","metadata":{"id":"csKLI0EXVi_j"},"source":["## Training\n","\n","The following cell trains a network on the semantic segmentation data. Copy your `IoU` function from the last assignment into `Problem2.py` so we can judge performance on the IoU score.\n","\n","\n","We provide a basic starter network `UNetStudent` which you will need to modify to get a full score. Try training the default network once, then making your own modifications to the network."],"id":"csKLI0EXVi_j"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cb1c6bc"},"outputs":[],"source":["def train_net_iou(net, trainloader, val_loader, device, num_epochs, optimizer, criterion):\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      # Train\n","      net.train()\n","      total_loss = 0\n","      i = 0\n","      loop = tqdm(trainloader)\n","      for data in loop:\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # Forward pass\n","          outputs = net(inputs)\n","          B, C, H, W = outputs.shape\n","          outputs = outputs.permute(0, 2, 3, 1)\n","          outputs = outputs.reshape(-1, C)\n","          labels = to_labels(labels, class_dict)\n","          labels = labels.long().view(-1)\n","\n","\n","          # backward + optimize\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          loop.set_description(\"Training\")\n","          total_loss += loss.detach().item()\n","          i += 1\n","          loop.set_postfix(loss=total_loss / i)\n","\n","      # Validate\n","      net.eval()\n","      loop = tqdm(val_loader)\n","      loop.set_description(\"Validation\")\n","      with torch.no_grad():\n","        all_targets = []\n","        all_preds = []\n","        for data in loop:\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","\n","            # Forward pass\n","            outputs = net(inputs)\n","            B, C, H, W = outputs.shape\n","            outputs = outputs.permute(0, 2, 3, 1)\n","            outputs = outputs.reshape(-1, C)\n","            labels = to_labels(labels, class_dict)\n","            labels = labels.long().view(-1)\n","\n","            # Targets and predictions for iou\n","            _, predicted = torch.max(outputs, 1)\n","            all_targets.append(labels)\n","            all_preds.append(predicted)\n","        all_preds = torch.cat(all_preds)\n","        all_targets = torch.cat(all_targets)\n","        iou, miou = IoU(all_targets, all_preds, 15)\n","\n","        # print statistics\n","        print(f'epochs: {epoch + 1} mIoU Val: {100 * miou.item():.3f}')\n","  print('Finished Training')\n","  return net"],"id":"8cb1c6bc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3d8832c"},"outputs":[],"source":["num_classes = 15\n","net = UNetStudent(num_classes).to(device)\n","# Loss function and optimizer\n","lr = 0.001\n","num_epochs = 5\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n","\n","# Training the first time will take a while. After the first pass through\n","# the data, training will speed up.\n","net = train_net_iou(net, trainloader, val_loader, device, num_epochs, optimizer, criterion)"],"id":"e3d8832c"},{"cell_type":"markdown","metadata":{"id":"7RtoI2q3WYlD"},"source":["## Save Weights\n","Run the next cell to save your weights."],"id":"7RtoI2q3WYlD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d87446c"},"outputs":[],"source":["# Save Weights\n","PATH = os.path.join(DATA_PATH, 'YourNet.pth')\n","torch.save(net.state_dict(), PATH)"],"id":"5d87446c"},{"cell_type":"markdown","metadata":{"id":"8kEDjg4QWeum"},"source":["# Visualize predictions\n","Next, we will load the saved weights and visualize some predictions compared to the ground truth."],"id":"8kEDjg4QWeum"},{"cell_type":"code","execution_count":null,"metadata":{"id":"06fe34a6"},"outputs":[],"source":["net = UNetStudent(num_classes).to(device)\n","net.load_state_dict(torch.load(PATH))"],"id":"06fe34a6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fd577d3e"},"outputs":[],"source":["# Convert colored image to labels\n","def label_to_image(label_img, color_to_label):\n","    B, H, W = label_img.shape\n","    colored_img = torch.zeros((B, H, W, 3), device=label_img.device, dtype=torch.uint8)\n","    for i, rgb in color_to_label.items():\n","        mask = label_img == i\n","        colored_img[mask, :] = torch.tensor(rgb, device=label_img.device, dtype=torch.uint8)\n","    return colored_img"],"id":"fd577d3e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4b36c67f"},"outputs":[],"source":["with torch.no_grad():\n","    # get some random training images\n","    dataiter = iter(trainloader)\n","    images, labels = next(dataiter)\n","\n","    # Make predictions\n","    # Forward pass\n","    outputs = net(images)\n","    B, C, H, W = outputs.shape\n","    outputs = outputs.permute(0, 2, 3, 1)\n","    # Targets and predictions for iou\n","    _, predicted = torch.max(outputs, 3)\n","    predicted_img = label_to_image(predicted, class_dict)\n","    # show labels\n","    print(\"Ground Truth\")\n","    demo_label = labels[0, :, :, :]\n","    imshow_labels(demo_label)\n","    # Show predictions\n","    print(\"Prediction\")\n","    demo_pred = predicted_img[0, :, :, :]\n","    imshow_labels(demo_pred)"],"id":"4b36c67f"},{"cell_type":"markdown","metadata":{"id":"SbOnIy8mWrqZ"},"source":["## Your Turn\n","Great! That was an easy assignment so far. Now comes the tricky part though. Now it is your turn to modify the training pipeline, hyper-parameters, and network architecture to improve the performance. Below are some ideas you can try:\n","\n","\n","\n","1.   Implement image_augmentation with random cropping and flipping.\n","2.   Add more convolution layers to each level of the U Net.\n","3.   Change the channel sizes within the U Net.\n","4.   Change the learning rate, batch size, and number of epochs.\n","5.   Add weights to the CrossEntropyLoss to weight classes with fewer occurences more.\n","6.   Modify the training code to save the model weights from the epoch with the highest mIoU on the validation set.\n","7.   There are many more options... you choose!\n","\n"],"id":"SbOnIy8mWrqZ"},{"cell_type":"code","source":["num_classes = 15\n","net = UNetStudent(num_classes).to(device)\n","\n","# Hyper-parameters\n","lr = 0.001\n","num_epochs = 5\n","batch_size = 2\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)"],"metadata":{"id":"WEyutxt5-Nq5"},"id":"WEyutxt5-Nq5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainset = ImageSegmentation(DATA_PATH, \"Train\", transform=transform_train(), device=device)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, collate_fn=trainset.collate_fn)\n","\n","valset = ImageSegmentation(DATA_PATH, \"Val\", transform=transform_test(), device=device)\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n","                                         shuffle=True, collate_fn=valset.collate_fn)"],"metadata":{"id":"XI2VoHdS-Mh-"},"id":"XI2VoHdS-Mh-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5027cde0"},"outputs":[],"source":["net = train_net_iou(net, trainloader, val_loader, device, num_epochs, optimizer, criterion)\n","torch.save(net.state_dict(), PATH)"],"id":"5027cde0"},{"cell_type":"markdown","metadata":{"id":"Rp-d83wRXCcp"},"source":["When you are happy with your results on the validation set, run the following cells to save the weights and generate predictions on the test set. The entire score from this assignment will be based on the mIoU as described above."],"id":"Rp-d83wRXCcp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d59f14f"},"outputs":[],"source":["net = UNetStudent(num_classes).to(device)\n","net.load_state_dict(torch.load(PATH))"],"id":"0d59f14f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxeWgQtqXU3m"},"outputs":[],"source":["testset = ImageSegmentation(DATA_PATH, \"Test\", transform=transform_test(), device=device)"],"id":"JxeWgQtqXU3m"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9cU0plmzXtuA"},"outputs":[],"source":["# Test\n","i = 0\n","net.eval()\n","save_dir = os.path.join(DATA_PATH, \"Test\", \"Problem2_Predictions\")\n","if not os.path.exists(save_dir):\n","  os.mkdir(save_dir)\n","\n","i = 0\n","with torch.no_grad():\n","  for inputs, __ in iter(testset):\n","    # We are only evaluating every tenth image due to memory constraints on\n","    # Auto-grader\n","    if i % 10 == 0:\n","      C, H, W = inputs.shape\n","      outputs = net(inputs.view(1, C, H, W).to(device))\n","      B, C, H, W = outputs.shape\n","      outputs = outputs.permute(0, 2, 3, 1)\n","      predictions = outputs.argmax(dim=3).view(H, W)\n","      predictions_np = predictions.detach().cpu().numpy().astype(np.uint8)\n","      save_path = os.path.join(save_dir, str(i).zfill(6) + \".label\")\n","      predictions_np.tofile(save_path)\n","    i += 1"],"id":"9cU0plmzXtuA"},{"cell_type":"markdown","metadata":{"id":"fV_89iRta_Ho"},"source":["# Submission\n","Great job! Submit the predictions folder as a zip file called `Problem2_Predictions.zip`, as well as your solution file `Problem2.py` and colab notebook `UNet.ipynb`."],"id":"fV_89iRta_Ho"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}