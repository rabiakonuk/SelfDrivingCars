{"cells":[{"cell_type":"markdown","metadata":{"id":"0j_sCGGcyYFo"},"source":["# NAVARCH 565 FA 23 Homework 4\n","\n","Before we start, please put your name and UMID in following format\n","\n",": Firstname LASTNAME, #00000000   //   e.g.) Joey WILSON, #12345678"]},{"cell_type":"markdown","metadata":{"id":"WM3DEQ31yaGi"},"source":["**Your Answer:**   "]},{"cell_type":"markdown","metadata":{"id":"uEaOn1XIydUh"},"source":["# Objectives\n","\n","In this assignment, we will learn a fundamental technology for operating on point clouds. Compared to images, point clouds are difficult since they are an un-ordered set. While point clouds can be discretized in the form of a voxel grid to allow more traditional convolutional approaches, such a discretization is generally lossy. PointNet solved this problem by introducing a network which directly processes point clouds.\n","\n","Before we start, take a few minutes to read through PointNet: https://arxiv.org/abs/1612.00593"]},{"cell_type":"markdown","metadata":{"id":"Iya7eQtfvYxA"},"source":["# Grading\n","\n","Grading for this assignment will consist of three main sections.\n","\n","1.   Implementation of PointNet architecture. We will guide you through constructing a basic PointNet by dividing the network into small modules. When testing, we will create an instance of your class and attempt to load weights from our PointNet into your PointNet. If any layers do not match or have different names, the test will fail. We will then feed some dummy data to check the forward pass by comparing with our output.\n","2.   Test set performance. We will load your predictions as a zip file titled `Problem1_Predictions.zip` and assign a score based on the mIoU metric. The problem is out of 150 points with 50 points of extra credit, assigned as:\n","$$\n","\\text{score} = 200 \\frac{\\text{mIoU}}{10}\n","$$\n","where a mIoU of 10% achieves all extra credit, and a mIoU of 7.5% achieves full credit.\n","3.   mIoU implementation. We will check that the output given some data matches our implementation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BK97EXRrzm8v"},"source":["# Setup Code\n","Before getting started we need to run some boilerplate code to set up our environment. You'll need to rerun this setup code each time you start the notebook.\n","\n","First, run this cell load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This allows us to edit `.py` source files, and re-import them into the notebook for a seamless editing and debugging experience."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wr1VNGrJyVlv"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"MXroXwBxYJoF"},"source":["### Google Colab Setup\n","\n","Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n","\n","Run the following cell to mount your Google Drive. Follow the link and sign in to your Google account (the same account you used to store this notebook!)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQ-bUAHnYKZD"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"1EZtosZ2zprf"},"source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below. If everything is working correctly then running the folowing cell should print the filenames from the assignment:\n","\n","```\n","['utils.py', 'PointNet.ipynb',  'Problem1.py', 'semantic_kitti.yaml']\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_j8EYJjzx_f"},"outputs":[],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 2023FA folder and put all the files under A4/PointNet folder, then '2023FA/A4/PointNet'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"2023FA/A4/PointNet\"\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sF1d_n9Lzz9A"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGuUJs9tz0jT"},"outputs":[],"source":["# Imports\n","import numpy as np\n","import torch\n","import yaml\n","from tqdm import tqdm\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"jjhec9MTz2qt"},"source":["Next we will check if a GPU is available"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxWVclEGz4pk"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"]},{"cell_type":"markdown","metadata":{"id":"nIFQk94qz628"},"source":["Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n","\n","```\n","Welcome to assignment 4!\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HXIZFQzz9Zs"},"outputs":[],"source":["from utils import *\n","from Problem1 import *\n","hello()\n","\n","py_path = os.path.join(GOOGLE_DRIVE_PATH, 'Problem1.py')\n","py_edit_time = time.ctime(os.path.getmtime(py_path))\n","print('Student_Solution.py last edited on %s' % py_edit_time)"]},{"cell_type":"markdown","metadata":{"id":"oq0E-fnXfEaX"},"source":["# Data Visualization\n","\n","In this assignment we will be working with point clouds from Semantic KITTI again. To get an understanding of how the data looks, return to A3 where we registered semantic point clouds together. Today we will be learning to segment the point clouds ourselves with semantic labels such as car, person, or road.\n","\n","Download the data from the following link and unzip it to a Data folder: https://curly-dataset-public.s3.us-east-2.amazonaws.com/NA565/PointNet/StudentData/PointNet.zip\n","\n","Move the `semantic_kitti.yaml`file into the Data folder.\n","\n","\n","\n","If the file paths are set correctly, we should be able to visualize a point cloud below.\n","\n","Notice how the data is dense close to the vehicle and sparse further away? The amount of data could cause problems for PointNet, which typically handles fewer than a hundred thousand points, so we used a voxel filter to pre-process the input. Now, the data contains at most one point per voxel with dimensions of 10 cm along each axis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqZ-1mO-iFkx"},"outputs":[],"source":["# First, load the learning map for Semantic KITTI\n","DATA_PATH = os.path.join(GOOGLE_DRIVE_PATH, \"Data\")\n","config_file = os.path.join(DATA_PATH, \"semantic_kitti.yaml\")\n","kitti_config = yaml.safe_load(open(config_file, 'r'))\n","# Label map\n","LABELS_REMAP = kitti_config[\"learning_map\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsivZp_ZgnZw"},"outputs":[],"source":["%matplotlib inline\n","\n","# File paths\n","demo_pc = os.path.join(DATA_PATH, \"Train\", \"velodyne_ds\", \"000000.bin\")\n","demo_label = os.path.join(DATA_PATH, \"Train\", \"labels_ds\", \"000000.label\")\n","# Obtain numpy arrays\n","demo_pc = np.fromfile(demo_pc, dtype=np.float32).reshape(-1, 4)\n","demo_label = np.fromfile(demo_label, dtype=np.int32).reshape(-1) & 0xFFFF\n","# Remap labels\n","label_remap = get_remap_lut(LABELS_REMAP)\n","demo_label = label_remap[demo_label]\n","\n","# Plot\n","plot_cloud(demo_pc, demo_label)"]},{"cell_type":"markdown","metadata":{"id":"oGI4ZSLgjL0H"},"source":["### PyTorch Imports and Parameters\n","\n","We need some imports for PyTorch to run, which are found in the code cell below. We also need to set some hyper-parameters. Don't worry about these for now, later you will get a chance to tune them.\n","\n","\n","\n","*   `batch_size` is the number of data examples within a mini-batch.\n","*   `lr` is the learning rate of the network.\n","*   `num_epochs` is the number of epochs, or times the network will train on each individual example.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Srgv2tGAjSPO"},"outputs":[],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJtPDlkQjVf-"},"outputs":[],"source":["batch_size = 2\n","lr = 0.001\n","num_epochs = 5"]},{"cell_type":"markdown","metadata":{"id":"0e9VJaUVjX3f"},"source":["### Data Loader\n","Next, we will create data loaders for the training and validation set. Take a look in `Problem1` at class `PointLoader` for some starter code. You will need to implement the `__getitem__` function, which takes an index and returns the point cloud and label. See the above code for help fetching the items from the files or remapping the labels. Note that we need to mask the label to remove instance labels, and remap to the training labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"revIz4uhmMxf"},"outputs":[],"source":["trainset = PointLoader(os.path.join(DATA_PATH, \"Train\"), label_remap,\n","                       device=device, data_split=\"Train\")\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=trainset.collate_fn)\n","\n","valset = PointLoader(os.path.join(DATA_PATH, \"Val\"), label_remap,\n","                     device=device, data_split=\"Val\")\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=1,\n","                                          shuffle=True,\n","                                          collate_fn=valset.collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8rpBGvYmrsy"},"outputs":[],"source":["# Now let's try loading and visualizing a point cloud to see if it worked.\n","dataiter = iter(trainloader)\n","velos, labels = next(dataiter)\n","plot_cloud(velos[0].detach().cpu().numpy(), labels[0].detach().cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"9msp8Vdrnt8d"},"source":["# Point Net\n","Now that we have data available, the next step is to train a network which can process the sparse points.\n","\n","**Basic Module**\n","\n","PointNet contains basic modules which learn to consolidate global information about the point set through two operations:\n","\n","\n","*   Feature transformations on individual points through MLPs.\n","*   Global and symmetric feature aggregation through max pooling.\n","\n","**Local and Global Information Aggregation**\n","\n","The above operations define the basic PointNet module. However, in semantic segmentation the task is to produce point-wise predictions and the output of the module is a global set of features. The solution to this problem taken by PointNet is to concatenate each point-wise feature vector with the global feature vector.\n","\n","**T-Net**\n","\n","In order to ensure the output semantic labels are invariant to geometric transformations, PointNet introduces a T-Net architecture which itself functions as a PointNet module. However, T-Net predicts an affine transformation matrix which is directly applied to the coordinates of the input points."]},{"cell_type":"markdown","metadata":{"id":"l0xHXJYqazZB"},"source":["## Encoder\n","\n","First, let us create an encoder module. The encoder module contains a series of an MLP with linear layers and ReLU nonlinearities designed to encode the points within a feature space. The input to the module will be a list of channel sizes (`cs`). The first layer will contain a linear layer from `cs[0]` to `cs[1]` followed by a batch norm and ReLU. The next layer will have a linear layer from `cs[1]` to `cs[2]`, etc. If `linear_out` is not none, add a linear layer after the MLP to create un-normalized predictions as the output of the network.\n","\n","For this module, you will need to understand the following functions:\n","\n","\n","1.   `torch.nn.Sequential()`\n","2.   `nn.Linear()`\n","3.   `nn.BathNorm1d()`\n","4.   `nn.ReLU()`\n","\n","\n","Implement `PointNetEncoder`. If it is working correctly, the following cell should return True. Note that this will only work in Google Colab, as behaviour on your local computer may be different."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdohRS0FoDmo"},"outputs":[],"source":["# Create an instance of the module\n","seed_torch()\n","net = PointNetEncoder([3, 64, 128, 1024]).to(device)\n","\n","# Set all parameters to one\n","with torch.no_grad():\n","  state_dict = net.state_dict()\n","  for param_tensor in state_dict:\n","      state_dict[param_tensor] = torch.ones_like(state_dict[param_tensor])\n","  net.load_state_dict(state_dict)\n","\n","# Dummy data\n","test_in = demo_pc[:1000, :3].reshape(2, -1, 3)\n","test_in = torch.from_numpy(test_in).to(device)\n","\n","test_out = torch.sum(net(test_in)).item()\n","\n","# If this works, you should see the following return True\n","if str(device) == \"cpu\":\n","  print(np.isclose(1071978.25, test_out))\n","else:\n","  print(np.isclose(1071978.25, test_out))"]},{"cell_type":"markdown","metadata":{"id":"f_iPBhu-dgVQ"},"source":["## Global and Local Aggregation\n","The PointNet encoder is useful for learning point-wise features, however there is currently no symmetric feature aggregation. In order to obtain symmetric feature aggregation, we will add a max-pooling layer after the encoder. Fill in `PointNetModule`, which uses a PointNet Encoder to learn point-wise features, followed by a max pooling to obtain global features as well as local and global feature aggregation.\n","\n","The input to the module is similar, including a list of encoder channel sizes and decoder channel sizes. In the initialization, create a `PointNetEncoder` MLP using `cs_en`, and a `PointNetEncoder` MLP using `cs_dec` with linear_out set to the number of classes. In the forward pass, first pass the input through the encoder MLP. Then apply max pooling over the points dimension to obtain global features. Finally, concatenate the point-wise features with the global features and apply the decoder MLP.\n","\n","Implement `PointNetModule`. If it works, the following cell should return `True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKqlapLrwjj6"},"outputs":[],"source":["seed_torch()\n","net = PointNetModule([3, 64, 128, 1024], [2048, 128, 64, 32]).to(device)\n","\n","# Set all parameters to one\n","with torch.no_grad():\n","  state_dict = net.state_dict()\n","  for param_tensor in state_dict:\n","      state_dict[param_tensor] = torch.ones_like(state_dict[param_tensor])\n","  net.load_state_dict(state_dict)\n","\n","# Dummy data\n","test_in = demo_pc[:1000, :3].reshape(2, -1, 3)\n","test_in = torch.from_numpy(test_in).to(device)\n","\n","test_out = torch.sum(net(test_in)).item()\n","\n","# If this works, the following should print True\n","if str(device) == \"cpu\":\n","  print(np.isclose(672943.1875, test_out))\n","else:\n","  print(np.isclose(672943.1875, test_out))"]},{"cell_type":"markdown","metadata":{"id":"EkEHOsSmfMDb"},"source":["## Training\n","\n","Now that we have a basic `PointNetModule`, let's try training it. Note that our network does not have a T-Net at this point so performance may be subpar. The first epoch will take a while to load all of the data, but performance will be significantly faster after the first epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZIXIkWPfWYY"},"outputs":[],"source":["def train_net(net, trainloader, val_loader, device, num_epochs, optimizer, criterion):\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      # Train\n","      net.train()\n","      total_loss = 0\n","      i = 0\n","      loop = tqdm(trainloader)\n","      for data in loop:\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # Forward pass\n","          outputs = net(inputs)\n","          B, N, C = outputs.shape\n","          outputs = outputs.view(-1, C)\n","          labels = labels.view(-1).long()\n","\n","          # backward + optimize\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          loop.set_description(\"Training\")\n","          total_loss += loss.item()\n","          i += 1\n","          loop.set_postfix(average_loss=total_loss/i)\n","\n","      # Validate\n","      num_correct = 0\n","      num_total = 0\n","      net.eval()\n","      loop = tqdm(val_loader)\n","      with torch.no_grad():\n","        for data in loop:\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            # Forward pass\n","            outputs = net(inputs)\n","            B, N, C = outputs.shape\n","            outputs = outputs.view(-1, C)\n","            labels = labels.view(-1).long()\n","            # Check correct\n","            _, predicted = torch.max(outputs, 1)\n","            num_correct += torch.sum(predicted == labels).item()\n","            num_total += predicted.shape[0]\n","\n","            loop.set_description(\"Validation\")\n","            loop.set_postfix(Acc=100*num_correct/num_total)\n","\n","      # print statistics\n","      print(f'epochs: {epoch + 1} Accuracy Val: {100 * num_correct / num_total:.3f}')\n","  print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPNtW6oVhPrC"},"outputs":[],"source":["# Training will be very slow on CPU, recommend using GPU\n","# Be patient with the first epoch if running in Google Colab.\n","# The first epoch takes extra time to fetch files.\n","seed_torch()\n","\n","lr = 0.001\n","num_epochs = 10\n","\n","net = PointNetModule([3, 32, 64, 128], [256, 128, 64]).to(device)\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n","\n","train_net(net, trainloader, val_loader, device, num_epochs, optimizer, criterion)\n","\n","# Save network\n","PATH = os.path.join(GOOGLE_DRIVE_PATH, 'PointNetModule.pth')\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"markdown","metadata":{"id":"2PXh-1n1rjEy"},"source":["## T-Net\n","Next, we will add the transformation network or T-Net to our PointNet module. The T-Net operates very similarly to the PointNet module, however it only operates on the global features to create a global 3x3 transformation matrix.\n","\n","In the initialization function, create a `PointNetEncoder` MLP to encode and decode the transformation. Also create a `PointNetModule` for the joint encoding operation. In the forward pass:\n","\n","\n","1.   Pass the input through the transformation encoder\n","2.   Apply max pooling to obtain global features.\n","3. Pass the global features through the transformation decoder to obtain the transformation.\n","4. Reshape the transfomation to Bx3x3  and add an identity matrix. The identity matrix creates a possible skip connection.\n","5. Apply the transformation to the input points to obtain transformed points, and feed the transformed points through the `PointNetModule` joint encoder.\n","\n","Fill in `PointNetFull`. If the T-Net is implemented correctly, the following cell will return `True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xl6Tn6Ac2PlJ"},"outputs":[],"source":["# Channel sizes\n","cs_t_en = [3, 32, 64]\n","cs_t_dec = [64, 32]\n","cs_enc = [3, 32, 64, 128]\n","cs_dec = [256, 128, 64, 32]\n","\n","# Create model\n","seed_torch()\n","net = PointNetFull(cs_enc, cs_dec, cs_t_en, cs_t_dec).to(device)\n","\n","# Set all parameters to one\n","with torch.no_grad():\n","  state_dict = net.state_dict()\n","  for param_tensor in state_dict:\n","      state_dict[param_tensor] = torch.ones_like(state_dict[param_tensor])\n","  net.load_state_dict(state_dict)\n","\n","test_in = demo_pc[:1000, :3].reshape(2, -1, 3)\n","test_in = torch.from_numpy(test_in).to(device)\n","\n","test_out = torch.sum(net(test_in)).item()\n","\n","# If this works, the following should print True\n","if str(device) == \"cpu\":\n","  print(np.isclose(668833.0, test_out))\n","else:\n","  print(np.isclose(668833.0, test_out))"]},{"cell_type":"markdown","metadata":{"id":"YPUJ_dRLG1_4"},"source":["Next, let's train the new network with the T-Net. You should see a slight difference in network performance, but do not worry if the difference is small. Later we will get a chance to improve the network further."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgvMRXZ7tGbI"},"outputs":[],"source":["# Training will be very slow on CPU, recommend using GPU\n","seed_torch()\n","\n","lr = 0.001\n","num_epochs = 10\n","\n","# Channel sizes\n","cs_t_en = [3, 32, 64]\n","cs_t_dec = [64, 32, 9]\n","cs_enc = [3, 32, 64, 128]\n","cs_dec = [256, 128, 64, 20]\n","net = PointNetFull(cs_enc, cs_dec, cs_t_en, cs_t_dec).to(device)\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n","\n","train_net(net, trainloader, val_loader, device, num_epochs, optimizer, criterion)"]},{"cell_type":"markdown","metadata":{"id":"s4mlVyZRzP9v"},"source":["## Visualization\n","Congratulations! You have now built your very first PointNet. Now we will visualize the predictions from your model on a point cloud from the data set. Hopefully it looks good!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jj5Eb6BpzcYj"},"outputs":[],"source":["# Load a sample of data\n","dataiter = iter(trainloader)\n","velos, labels = next(dataiter)\n","with torch.no_grad():\n","  # forward pass\n","  output = net(velos)\n","  probabilities = torch.nn.functional.softmax(output, dim=1)\n","  predictions = torch.argmax(probabilities, dim=2)\n","  predictions_np = predictions[0, :].detach().cpu().numpy()\n","  velo_pc = velos[0, :, :].detach().cpu().numpy()\n","\n","plot_cloud(velo_pc, predictions_np)"]},{"cell_type":"markdown","metadata":{"id":"-RNIpc9JZNq8"},"source":["# Mean IoU\n","Lastly, before you attempt to build the best PointNet you can, we need to choose a different evaluation metric. While accuracy can be an important metric, it does not provide information about per-class performance or the proportion of true positives to false positives. Instead, we will evaluate with the __intersection over union (IoU)__ metric.\n","\n","IoU = $\\frac{\\text{target} ⋂ prediction}{target ⋃ prediction}$\n","\n","Implement the `IoU` function in your python file. You will be given a Pytorch tensor for the predictions and targets as input, as well as the number of classes (`C`) in total. The function should return an array of size `C` containing the IoU for each category. In the event that there are none of a class in the targets, return 1 for the class. The function should return both a per-class IoU, and mean IoU. We will use the mIoU to evaluate your network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g23lYUXjb2CF"},"outputs":[],"source":["seed_torch()\n","\n","targets = torch.from_numpy(demo_label[40000:41000]).to(device)\n","predictions = torch.from_numpy(demo_label[41000:42000]).to(device)\n","\n","test_iou, miou = IoU(targets, predictions, 20)\n","\n","if str(device) == \"cpu\":\n","  print(np.isclose(0.6906423568725586, miou.item()))\n","else:\n","  print(np.isclose(0.6906423568725586, miou.item()))"]},{"cell_type":"markdown","metadata":{"id":"YR5G_9TGbirt"},"source":["# Your Turn!\n","Now it's your turn to create your own PointNet network. Try playing around with the number of layers in the encoders, the number of channels, epochs, batch sizes, and learning rate of the network. You can also add data augmentation to the data loader, such as random rotations and translations of the point cloud.\n","\n","Be careful not to modify the network classes as we will be grading these. We will also be grading your network on the test set of this point cloud semantic segmentation dataset. When you are happy with the performance of your network, go to the bottom of the notebook to save the weights and generate predictions on the test set.\n","\n","Note that vanilla PointNet has a difficult time with large-scale driving point clouds. In the PointNet paper, the authors propose to add another T-Net to the feature space which may help slightly increase performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUpOanBT5pzi"},"outputs":[],"source":["# Hyperparameters: try changing these\n","lr = 0.001\n","num_epochs = 5\n","\n","# Channel sizes: try changing these\n","cs_t_en = [3, 32, 64]\n","cs_t_dec = [64, 32]\n","cs_enc = [3, 32, 64, 128]\n","cs_dec = [256, 128, 64, 32]\n","\n","# Data loaders\n","trainset = PointLoader(os.path.join(DATA_PATH, \"Train\"), label_remap,\n","                       device=device, data_split=\"Train\")\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True,\n","                                          collate_fn=trainset.collate_fn)\n","\n","valset = PointLoader(os.path.join(DATA_PATH, \"Val\"), label_remap,\n","                     device=device, data_split=\"Val\")\n","val_loader = torch.utils.data.DataLoader(valset, batch_size=1,\n","                                          shuffle=True,\n","                                          collate_fn=valset.collate_fn)\n","\n","testset = PointLoader(os.path.join(DATA_PATH, \"Test\"), label_remap,\n","                     device=device, data_split=\"Test\")\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=1,\n","                                          shuffle=False,\n","                                          collate_fn=testset.collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EHjgvxO6e_p"},"outputs":[],"source":["def train_net_iou(net, trainloader, val_loader, device, num_epochs, optimizer, criterion):\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      # Train\n","      net.train()\n","      total_loss = 0\n","      i = 0\n","      loop = tqdm(trainloader)\n","      for data in loop:\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = data\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # Forward pass\n","          outputs = net(inputs)\n","          B, N, C = outputs.shape\n","          outputs = outputs.view(-1, C)\n","          labels = labels.view(-1).long()\n","\n","\n","          # backward + optimize\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          loop.set_description(\"Training\")\n","          total_loss += loss.item()\n","          i += 1\n","          loop.set_postfix(loss=total_loss / i)\n","\n","      # Validate\n","      all_targets = []\n","      all_preds = []\n","      net.eval()\n","      loop = tqdm(val_loader)\n","      loop.set_description(\"Validation\")\n","      with torch.no_grad():\n","        for data in loop:\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","\n","            # Forward pass\n","            outputs = net(inputs)\n","            B, N, C = outputs.shape\n","            outputs = outputs.view(-1, C)\n","            labels = labels.view(-1).long()\n","\n","            # Targets and predictions for iou\n","            _, predicted = torch.max(outputs, 1)\n","            all_targets.append(labels)\n","            all_preds.append(predicted)\n","      iou, miou = IoU(torch.concatenate(all_targets), torch.concatenate(all_preds), 20)\n","\n","      # print statistics\n","      print(f'epochs: {epoch + 1} mIoU Val: {100 * miou.item():.3f}')\n","  print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yeyEaTOag0ul"},"outputs":[],"source":["# Training will be very slow on CPU, recommend using GPU\n","seed_torch()\n","\n","\n","net = PointNetFull(cs_enc, cs_dec, cs_t_en, cs_t_dec).to(device)\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n","\n","train_net_iou(net, trainloader, val_loader, device, num_epochs, optimizer, criterion)"]},{"cell_type":"markdown","metadata":{"id":"wMIhi06_8ZhB"},"source":["# Submission\n","Congratulations on finishing the first problem of Assignment 4! Run the following code to save your weights of your network and generate predictions on the test set. For your submission, we will need your colab notebook, weights, python file, and predictions on the test set.\n","\n","Make sure to submit the predictions as a zip file named `Problem1_Predictions.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjrXgmCl-hAk"},"outputs":[],"source":["# Save Weights\n","PATH = os.path.join(GOOGLE_DRIVE_PATH, 'YourNet.pth')\n","torch.save(net.state_dict(), PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-Hh-fY_8nIp"},"outputs":[],"source":["# Generate Predictions\n","net.load_state_dict(torch.load(PATH))\n","\n","# Test\n","i = 0\n","net.eval()\n","save_dir = os.path.join(DATA_PATH, \"Test\", \"Problem1_Predictions\")\n","if not os.path.exists(save_dir):\n","  os.mkdir(save_dir)\n","with torch.no_grad():\n","  for inputs, __ in iter(testset):\n","      # Get the inputs; data is a list of [inputs, labels]\n","      input = torch.from_numpy(inputs).to(device)\n","      input = torch.unsqueeze(input, 0)\n","\n","      # Forward\n","      output = net(input).squeeze(0)\n","      _, predicted = torch.max(output, 1)\n","\n","      # Save predictions\n","      if i % 10 == 0:\n","        predictions_np = predicted.detach().cpu().numpy().astype(np.int32)\n","        save_path = os.path.join(save_dir, str(i).zfill(6) + \".label\")\n","        predictions_np.tofile(save_path)\n","      i += 1"]},{"cell_type":"markdown","metadata":{"id":"V2u9T1nahN-K"},"source":["# Next Steps\n","For future reading of research standards, check out the articles below:\n","\n","\n","*   PointNet++ (https://arxiv.org/abs/1706.02413) directly improves upon PointNet.\n","*   KPConv (https://arxiv.org/abs/1904.08889) designs point convolution which operates directly on points.\n","*   PointPillars (https://arxiv.org/abs/1812.05784) shows that a regular grid structure can be combined with PointNet for improved performance.\n","\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}