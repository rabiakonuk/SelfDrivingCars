{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Models and Messages\n",
    "\n",
    "There are two types of language models:\n",
    "\n",
    "**LLM:** The underlying model takes a string as input and returns a string.\n",
    "\n",
    "**ChatModel:** The underlying model takes a list of messages as input and returns a message.\n",
    "\n",
    "Strings are simple, but what exactly are messages? The base message interface is defined by `BaseMessage`, which has two required attributes:\n",
    "\n",
    "- `content`: The content of the message. Usually a string.\n",
    "- `role`: The entity from which the `BaseMessage` is coming.\n",
    "\n",
    "`LangChain` provides several objects to easily distinguish between different roles:\n",
    "\n",
    "- `HumanMessage`: A `BaseMessage` coming from a human/user.\n",
    "- `AIMessage`: A `BaseMessage` coming from an AI/assistant.\n",
    "- `SystemMessage`: A `BaseMessage` coming from the system.\n",
    "- `FunctionMessage` / `ToolMessage`: A `BaseMessage` containing the output of a function or tool call.\n",
    "\n",
    "If none of those roles sound right, there is also a `ChatMessage` class where you can specify the role manually.\n",
    "\n",
    "`LangChain` provides a common interface that's shared by both LLMs and ChatModels. However, it's useful to understand the difference to most effectively construct prompts for a given language model.\n",
    "\n",
    "The simplest way to call an LLM or ChatModel is using `.invoke()`, the universal synchronous call method for all LangChain Expression Language (LCEL) objects:\n",
    "\n",
    "- `LLM.invoke`: Takes in a string, returns a string.\n",
    "- `ChatModel.invoke`: Takes in a list of `BaseMessage`, returns a `BaseMessage`.\n",
    "\n",
    "The input types for these methods are more general than this, but for simplicity here, we can assume LLMs only take strings, and Chat models only take lists of messages. Check out the \"Go deeper\" section below to learn more about model invocation.\n",
    "\n",
    "Let's see how to work with these different types of models and these different types of inputs. First, let's import an LLM and a ChatModel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List \n",
    "\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langserve import add_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=\"key")\n",
    "chat_model = ChatOpenAI(openai_api_key=\"key")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Building a decision-making module for a self-driving car requires careful consideration of various factors, including safety, efficiency, legality, and ethics. Here's an outline of the key components and considerations that would typically go into designing such a module:\\n\\n1. Perception: The module would incorporate sensors (such as cameras, lidar, radar) to gather information about the car's surroundings, including other vehicles, pedestrians, and road conditions. Perception algorithms would then process this data to build an understanding of the environment.\\n\\n2. Localization and Mapping: The module would use localization techniques (e.g., GPS, inertial measurement units) to determine the car's position accurately. Simultaneously, it would create and update a detailed map of the surroundings, including lane markings, traffic signs, and traffic lights.\\n\\n3. Planning: The module would generate a high-level plan based on the current situation, taking into account the car's destination, traffic rules, and other constraints. It would determine the desired path, lane changes, and actions needed to reach the destination efficiently.\\n\\n4. Decision-Making: This is a critical aspect. The module would evaluate various factors, such as traffic conditions, speed limits, signal timing, pedestrian movements, and other vehicles' behavior. It would prioritize safety and legality while making decisions on acceleration, braking, lane changes, and interactions with other road users.\\n\\n5. Predictive Modeling: The module would analyze the behavior and intentions of other road users and predict their future movements to anticipate potential hazards or conflicts. This would help the self-driving car make proactive decisions and avoid accidents.\\n\\n6. Ethics and Human Values: The module would incorporate ethical considerations, such as avoiding harm to pedestrians or passengers, following traffic rules, and prioritizing safety over efficiency. These decisions would be based on a combination of legal requirements, societal consensus, and predefined ethical guidelines.\\n\\n7. Real-Time Adaptation: The module should continuously monitor the environment and adapt its decisions based on changing conditions, unexpected events, or new information. It should be able to handle dynamic scenarios and adjust its behavior accordingly.\\n\\n8. Testing and Validation: Extensive testing, including simulation, controlled track tests, and real-world scenarios, would be necessary to ensure the decision-making module performs reliably, accurately, and safely.\\n\\nIt's important to note that developing a decision-making module for a self-driving car is a complex and ongoing research topic. It requires a multidisciplinary approach, involving experts in robotics, artificial intelligence, computer vision, control systems, and ethics to build a reliable and trustworthy system.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I want to make you the decision making module of a self driving car.\"\n",
    "messages = [HumanMessage(content=text, is_human=True)]\n",
    "llm.invoke(text)\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the characteristics of the LLM decision making module of a self driving car?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What are the characteristics of the {product} of a self driving car?\")\n",
    "prompt.format(product=\"LLM decision making module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a perfect driver that drives San Francisco to Los Angeles.'),\n",
       " HumanMessage(content='I want to go to Los Angeles.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a perfect driver that drives {start_point} to {end_point}.\"\n",
    "human_template = \"{text}\"\n",
    "chat_promt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "chat_promt.format_messages(start_point=\"San Francisco\", end_point=\"Los Angeles\", text=\"I want to go to Los Angeles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
